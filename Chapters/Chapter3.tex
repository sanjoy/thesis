\chapter{Compiling for Energy Efficiency}

\label{Chapter3}

\lhead{Chapter 3. \emph{Compiling for Energy Efficiency}}

In this chapter we look into transformations that may be automatically
done by a compiler to improve the energy profile of a program.  For a
concrete example of such an optimization, consider the C function
shown below

\begin{ccode}
long access_memory(long *buf) {
  return buf[0] + buf[1] + buf[2] + buf[3] +
         buf[4] + buf[5] + buf[6] + buf[7];
}
\end{ccode}

Both

\begin{ccode}
access_memory_a:
  movq    (%rdi),   %rax
  addq    8(%rdi),  %rax
  addq    24(%rdi), %rax
  addq    16(%rdi), %rax
  addq    48(%rdi), %rax
  addq    56(%rdi), %rax
  addq    40(%rdi), %rax
  addq    32(%rdi), %rax
  ret
\end{ccode}

and

\begin{gascode}
access_memory_b:
  movq    (%rdi),   %rax
  addq    8(%rdi),  %rax
  addq    16(%rdi), %rax
  addq    24(%rdi), %rax
  addq    32(%rdi), %rax
  addq    40(%rdi), %rax
  addq    48(%rdi), %rax
  addq    56(%rdi), %rax
  ret
\end{gascode}

are semantically correct ways of compiling the C function into
assembly.  However, the power profile of \texttt{access\_memory\_a} is
better than that of \texttt{access\_memory\_b}; as can be seen when
they are plugged into a test harness that executes them a thousand
times and profiled (for complete source code, please see
\refsec{code:direct-mem} for \texttt{access\_memory\_b} and
\refsec{code:grey-mem} for \texttt{access\_memory\_a}):

\begin{center}
  \begin{tabular}{ | c | c | }
    \hline
    \multicolumn{2}{|c|}{\texttt{access\_memory\_a}} \\
    \hline

    \textbf{Metric} & \textbf{Value} \\
    \hline

    Instruction Count &  102895 \\
    $E_{cpu\_instr}$ & 4.755959e+08 \\
    $E_{cpu\_data}$ & 5.111352e+08 \\
    $E_{mem\_instr}$ &  -1.235286e+08 \\
    $E_{mem\_data}$ & -1.507346e+07 \\
    $E_{total}$ & 8.481289e+08 \\
    \hline
  \end{tabular}
  \quad
  \begin{tabular}{ | c | c | }
    \hline
    \multicolumn{2}{|c|}{\texttt{access\_memory\_b}} \\
    \hline

    \textbf{Metric} & \textbf{Value} \\
    \hline

    Instruction Count &  102895 \\
    $E_{cpu\_instr}$ &  4.797092e+08 \\
    $E_{cpu\_data}$ &  5.426003e+08 \\
    $E_{mem\_instr}$ &  -1.240740e+08 \\
    $E_{mem\_data}$ &  -2.320418e+07 \\
    $E_{total}$ & 8.750314e+08 \\
    \hline
  \end{tabular}
\end{center}

The results are understandable, in \texttt{access\_memory\_a} the
addresses form a Gray code in their upper 61 bits and have a switching
cost of one bit flip per new memory read, while
\texttt{access\_memory\_b} incurs an average of two bit flips in the
bus per memory read.  This is clearly reflected in $E_{cpu\_data}$.

\section{Better Instruction Selection}

Since the choice of instruction directly influences the
base-instruction energy cost, it follows that an energy aware
instruction scheduler might be able to improve the energy profile of
the code generated.  Unfortunately, this approach didn't work as
expected; here we describe our implementation and our views on why it
wasn't effective.

\subsection{LLVM's Instruction Selector}

Like almost everything in llvm, the instruction selector is modeled as
a pass that runs on a \texttt{MachineFunction}.  Each target,
including x86, registers its own instruction selector.

Instead of directly encoding repetitive architecture specific
information in C++, llvm stores such data in \texttt{*.td}
files. During \textit{build} time, such information is read out using
\texttt{tablegen} (we also used this in \refsec{sec:pintool-tablegen})
and emitted as source code that is then compiled along with the rest
of llvm. This method gives llvm the flexibility of encoding domain
specific information succinctly without sacrificing performance.  In
the current situation, llvm uses the \texttt{tablegen} infrastructure
to implement a code-generator-generator (Chapter 6, Muchnick
\cite{muchnick}). The patterns and the machine code they correspond to
are read in by \texttt{tablegen} (a program using the
\texttt{tablegen} library, rather) and converted into a C++
instruction selector.  The instruction selector is modelled as a
target independent \textit{interpreter} with an architecture specific
\textit{program} (an array of opcodes) generated by \texttt{tablegen}.

The input to the instruction selector is a dependence DAG (called a
\textit{SelectionDAG} in llvm) of instructions, and it outputs a DAG
with nodes marked with the machine opcode llvm selected for them.
More detailed documentation about the entire code generation process
is available at http://llvm.org/docs/CodeGenerator.html.

\subsection{Incorporating Energy Costs}

A dependence DAG doesn't usually correspond to a unique sequence of
instructions.  For instance, in the x86 ISA, the dependence DAG shown
in \reffig{fig:example-dag} can be lowered to either an \texttt{lea}
instruction or a \texttt{mul} followed by an \texttt{add} instruction.
This ambiguity is resolved by assigning a \textit{cost} heuristic to
the instruction component of each pattern (for more details, please
see Muchnick, Chapter 6 \cite{muchnick}).

\begin{figure}[htbp]
  \centering
  \includegraphics[width=125px]{Figures/example-dag.eps}
  \rule{35em}{0.3pt}
  \caption{An Example Dependence DAG (not an llvm
    \textit{SelectionDAG})}
  \label{fig:example-dag}
\end{figure}

In our attempt, we modified this cost to take into account the power
cost of each instruction.  Since we did not have concrete values for
per-instruction energy costs; we used arbitrary (but reasonable)
values.

It turns out that llvm, with these modified values, generates exactly
the same code for the sorting benchmarks (see
\refsec{code:sorting-benchmark}) as without.  While it is possible
that we generate better code in some very specific, synthetic
benchmarks; we doubt such benefits will carry over to real-world
workloads.

\subsubsection{Rationale for Non-Effectiveness}

The issue at work here is that similar instructions consume same
amounts of energy in our model.  In other words, finding two sequences
of instructions semantically equivalent to each other but sufficiently
different to have different energy profiles is an exception than the
rule.  Such instances are all the more rare once the \textit{normal}
compiler passes have been run -- for instance, our model recognizes
shifting and rotating to consume a lesser (different, to be pedantic)
amount of energy than multiplication; but the usual optimizations will
already have transformed multiplies to shifts whenever possible.

\section{Better Instruction Scheduling}

(Work in progress).

\subsection{LLVM's Instruction Scheduler}

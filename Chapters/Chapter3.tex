\chapter{Compiling for Energy Efficiency}

\label{Chapter3}

\lhead{Chapter 3. \emph{Compiling for Energy Efficiency}}

In this chapter we look into transformations that may be automatically
done by a compiler to improve the energy profile of a program.  For a
concrete example of such an optimization, consider the C function
shown below

\begin{ccode}
long access_memory(long *buf) {
  return buf[0] + buf[1] + buf[2] + buf[3] +
         buf[4] + buf[5] + buf[6] + buf[7];
}
\end{ccode}

Both

\begin{gascode}
access_memory_a:
  movq    (%rdi),   %rax
  addq    8(%rdi),  %rax
  addq    24(%rdi), %rax
  addq    16(%rdi), %rax
  addq    48(%rdi), %rax
  addq    56(%rdi), %rax
  addq    40(%rdi), %rax
  addq    32(%rdi), %rax
  ret
\end{gascode}

and

\begin{gascode}
access_memory_b:
  movq    (%rdi),   %rax
  addq    8(%rdi),  %rax
  addq    16(%rdi), %rax
  addq    24(%rdi), %rax
  addq    32(%rdi), %rax
  addq    40(%rdi), %rax
  addq    48(%rdi), %rax
  addq    56(%rdi), %rax
  ret
\end{gascode}

are semantically correct ways of compiling the C function into
assembly.  However, the power profile of \texttt{access\_memory\_a} is
better than that of \texttt{access\_memory\_b}; as can be seen when
they are plugged into a test harness that executes them a thousand
times and profiled (for complete source code, please see
\refsec{code:direct-mem} for \texttt{access\_memory\_b} and
\refsec{code:grey-mem} for \texttt{access\_memory\_a}):

\begin{figure}[htbp]
  \centering

  \begin{tabular}{ | c | c | }
    \hline
    \multicolumn{2}{|c|}{\texttt{access\_memory\_a}} \\
    \hline

    \textbf{Metric} & \textbf{Value} \\
    \hline

    Instruction Count &  102895 \\
    $E_{cpu\_instr}$ & 4.755959e+08 \\
    $E_{cpu\_data}$ & 5.111352e+08 \\
    $E_{mem\_instr}$ &  -1.235286e+08 \\
    $E_{mem\_data}$ & -1.507346e+07 \\
    $E_{total}$ & 8.481289e+08 \\
    \hline
  \end{tabular}
  \quad
  \begin{tabular}{ | c | c | }
    \hline
    \multicolumn{2}{|c|}{\texttt{access\_memory\_b}} \\
    \hline

    \textbf{Metric} & \textbf{Value} \\
    \hline

    Instruction Count &  102895 \\
    $E_{cpu\_instr}$ &  4.797092e+08 \\
    $E_{cpu\_data}$ &  5.426003e+08 \\
    $E_{mem\_instr}$ &  -1.240740e+08 \\
    $E_{mem\_data}$ &  -2.320418e+07 \\
    $E_{total}$ & 8.750314e+08 \\
    \hline
  \end{tabular}

\end{figure}

The results are understandable, in \texttt{access\_memory\_a} the
addresses form a Gray code in their upper 61 bits and have a switching
cost of one bit flip per new memory read, while
\texttt{access\_memory\_b} incurs an average of two bit flips in the
bus per memory read.  This is clearly reflected in $E_{cpu\_data}$.

\section{Energy Aware Instruction Selection}

Since the choice of instruction directly influences the
base-instruction energy cost, it follows that an energy aware
instruction scheduler might be able to improve the energy profile of
the code generated.  Unfortunately, this approach didn't work as
expected; here we describe our implementation and our views on why it
wasn't effective.

\subsection{LLVM's Instruction Selector}

Like almost everything in llvm, the instruction selector is modeled as
a pass that runs on a \texttt{MachineFunction}.  Each target,
including x86, registers its own instruction selector.

Instead of directly encoding repetitive architecture specific
information in C++, llvm stores such data in \texttt{*.td}
files. During \textit{build} time, such information is read out using
\texttt{tablegen} (which we used in \refsec{sec:pintool-tablegen}) and
emitted as source code that is then compiled along with the rest of
llvm. This method gives llvm the flexibility of encoding domain
specific information succinctly without sacrificing performance.  In
the current situation, llvm uses the \texttt{tablegen} infrastructure
to implement a code-generator-generator (Chapter 6, Muchnick
\cite{muchnick}). The patterns and the machine code they correspond to
are read in by \texttt{tablegen} (a program using the
\texttt{tablegen} library, rather) and converted into a C++
instruction selector.  The instruction selector is modelled as a
target independent \textit{interpreter} with an architecture specific
\textit{program} (an array of opcodes) generated by \texttt{tablegen}.

The input to the instruction selector is a dependence DAG (called a
\textit{SelectionDAG} in llvm) of instructions, and it outputs a DAG
with nodes marked with the machine opcode llvm selected for them.
More detailed documentation about the entire code generation process
is available at http://llvm.org/docs/CodeGenerator.html.

\subsection{Incorporating Energy Costs}

A dependence DAG doesn't usually correspond to a unique sequence of
instructions.  For instance, in the x86 ISA, the dependence DAG shown
in \reffig{fig:example-dag} can be lowered to either an \texttt{lea}
instruction or a \texttt{mul} followed by an \texttt{add} instruction.
This ambiguity is resolved by assigning a \textit{cost} heuristic to
the instruction component of each pattern (for more details, please
see Muchnick, Chapter 6 \cite{muchnick}).

\begin{figure}[htbp]
  \centering
  \includegraphics[width=125px]{Figures/example-dag.eps}
  \rule{35em}{0.3pt}
  \caption{An Example Dependence DAG (not an llvm
    \textit{SelectionDAG})}
  \label{fig:example-dag}
\end{figure}

In our attempt, we modified this cost to take into account the power
cost of each instruction.  Since we did not have concrete values for
per-instruction energy costs; we used arbitrary (but reasonable)
values.

It turns out that llvm, with these modified values, generates exactly
the same code for the sorting benchmarks (see
\refsec{code:sorting-benchmark}) as without.  While it is possible
that we generate better code in some very specific, synthetic
benchmarks; we doubt such benefits will carry over to real-world
workloads.

\subsubsection{Rationale for Non-Effectiveness}

The issue at work here is that similar instructions consume same
amounts of energy in our model.  In other words, finding two sequences
of instructions semantically equivalent to each other but sufficiently
different to have different energy profiles is an exception than the
rule.  Such instances are all the more rare once the \textit{normal}
compiler passes have been run -- for instance, our model recognizes
shifting and rotating to consume a lesser (different, to be pedantic)
amount of energy than multiplication; but the usual optimizations will
already have transformed multiplies to shifts whenever possible.

\section{Energy Aware Instruction Scheduling}

LLVM's instruction scheduler assigns an ordering to the dependence DAG
after it is annotated with concrete machine instructions by the
instruction selector.  In other words, it chooses one of the many
possible topological sorts of the dependence DAG with an aim to
generate \textit{better} machine code, by some metric.  For instance,
an instruction scheduler may use instruction itineraries (for the
target micro-architecture) to schedule instructions attempting to
minimize pipeline stalls.  In this section, we describe our attempt to
get llvm's instruction scheduler schedule the dependence DAG to the
effect of reducing inter-instruction energy costs.

LLVM schedules instructions on two occasions -- before and after
register allocation.  Before register allocation, it uses a register
pressure reduction list scheduler\footnote{See
  llvm/lib/CodeGen/SelectionDAG/ScheduleDAGRRList.cpp} and after
register allocation, it optionally runs a priority-queue based
scheduling pass\footnote{See
  llvm/lib/CodeGen/PostRASchedulerList.cpp}.

\subsection{Reducing Inter-Instruction Energy Cost}

We postulated that the following kinds of inter-instruction energy
costs are amenable to reduction by an energy-aware instruction
scheduler.

\begin{description}
  \item[Data Address Switching Costs] \hfill \\ Data address switching
    costs, quantified as \textit{data\_addr\_cpu\_wt\_hamming} and
    \textit{data\-\_addr\_cpu\_wt\_hamming} in
    \refsec{sec:traits-desc} are the switching costs associated
    with the changing address in the memory bus during reads and
    writes.

  \item[Instruction Value Switching Costs] \hfill \\ The actual value
    of the instruction, in its native x86 encoding, contributes to
    $E_{mem\_inst}$ (see \refsec{sec:traits-desc}).  This can be
    reduced by taking into account the hamming distances of the
    instructions to be scheduled in the post-register allocation
    scheduler.  We get hold of the actual instruction encoding by
    JIT-compiling the function in advance while keeping track of what
    each scheduled node gets compiled to.
\end{description}

The implementation for both the above heuristics are similar: llvm
uses a priority queue of available instructions to choose the next,
most viable instruction.  We teach the priority queue to take into
account the hamming distance between the instruction just emitted.
The instruction \textit{just} emitted is either the instruction that
will be executed right after the chosen in the basic block (when
scheduling bottom-up) or the instruction executed just before the
chosen instruction (when scheduling top-down).  The actual direction
doesn't matter since hamming distance is symmetric.

\subsection{Results}

We made the above changes to llvm's instruction scheduler and profiled
the code generated from our sorting benchmarks and some C++ compiler
benchmarks from Adobe \cite{adobe-cpp}.

While we did not see any significant change in the energy profiles of
the sorting benchmarks (less than 0.01\%), we noticed some improvement
in the switching energy profiles\footnote{Generated by selectively
  assigning non-zero values only to data\_addr\_cpu\_wt\_hamming,
  inst\_value\_mem\_wt\_hamming and data\_addr\_mem\_wt\_hamming} of
the Adobe C++ benchmarks; shown in \reftab{fig:improvements}.

\begin{figure}[htbp]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \begin{tabular}{| c | c | c | c |}
    \hline
    \textbf{Benchmark} & \textbf{Normal} &
    \textbf{Energy Optimized} & \textbf{\%-age improvement} \\
    \hline

    loop-unroll & 330756521984.00 & 328669986816.00 & 0.63\% \\
    stepanov-vector & 35246866432.00 & 35049050112.00 & 0.56\% \\
    stepanov-abstraction & 22554845184.00 & 22546640896.00 & 0.03\% \\
    \hline
  \end{tabular}
  \caption{Improvements in energy profile}
  \label{fig:improvements}
\end{figure}

We attribute this discrepancy to the fact that the Adobe C++ compiler
benchmarks exposes more opportunities and freedom for reordering
instructions than our simplistic sorting benchmarks.

As expected, optimizing for energy efficiency affects the runtime of
the program -- the scheduler is no longer free to maximize instruction
level parallelism, for example.  We can see this in
\reftab{fig:performance-cost}.

\begin{figure}[htbp]
  \centering
  \renewcommand{\arraystretch}{1.5}

  \begin{tabular}{| c | c | c | c |}
    \hline
    \textbf{Benchmark} & \textbf{Normal} &
    \textbf{Energy Optimized} & \textbf{\%-age decline} \\ \hline
    
    loop-unroll & 120937800 & 120257871 & -0.6 \% \\
    stepanov-vector & 7574589 & 7585044 & 0.1 \% \\
    stepanov-abstraction & 3894723 & 3927411 & 0.8 \% \\
    \hline
  \end{tabular}
  \caption{Decline in the runtime performance of the compiled
    executable in terms of CPU ticks (as reported by the
    \texttt{rdtsc} instruction)}
  \label{fig:performance-cost}
\end{figure}

Interestingly, the modified scheduler improves both the energy profile
\textit{and} the tick count for the \textit{loop-unroll} benchmark.

\section{Future Work}

\begin{description}

\item[Code Placement] \hfill \\ Since there is a cost associated with
  switching in the instruction address bus, we may be able to improve
  the energy profile of generated code by optimizing the actual
  locations in the \texttt{.text} section the machine code is
  generated into.

\item[Integration with the Operating System] \hfill \\ A lot of the
  energy consumption is driven by factors within the control of the
  underlying operating system.  For instance, an energy aware loader
  should be able to reduce energy consumption by intelligently mapping
  the executable sections to reduce costs due to the instruction
  address bus.  Unfortunately, exploring an energy-conscious operation
  system is well beyond the scope of this work.

\end{description}
